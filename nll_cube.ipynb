{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "DEFAULT_SEED = 42\n",
    "\n",
    "from gaussian import MultivariateNormal, DynamicMultivariateNormal, VarianceExploding, VariancePreserving, SubVariancePreserving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cube_vertices(dim, side_len=1.0, var=1e-2):\n",
    "    vertices1d = np.array([0.0, side_len])\n",
    "    all_vertices1d = vertices1d.reshape(1, 2).repeat(dim, axis=0)\n",
    "    all_vertices = np.meshgrid(*all_vertices1d)\n",
    "    vertices = np.stack(all_vertices, axis=-1).reshape(-1, dim)\n",
    "    var = var * np.eye(dim)\n",
    "    return [DynamicMultivariateNormal(dim, vertex, var) for vertex in vertices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_quasi_exact_nll(\n",
    "    mix, prior, n_data=10_000, batch_size=1_000, t_min=1e-6, tf=1.0, seed=DEFAULT_SEED\n",
    "):\n",
    "    def flat_extended_ode(t, x_cumdiv_flat):\n",
    "        x, _ = np.split(x_cumdiv_flat.reshape(-1, mix.dim + 1), [mix.dim], -1)\n",
    "        dx, dlogp = mix.extended_ode(t, x)\n",
    "        return np.concatenate([dx, dlogp], 1).flatten()\n",
    "\n",
    "    def solve_batch(x_init):\n",
    "        n_data = x_init.shape[0]\n",
    "        delta_logp = np.zeros((n_data, 1))\n",
    "        x_logp_init = np.concatenate([x_init, delta_logp], axis=1).flatten()\n",
    "\n",
    "        solve_params = dict(rtol=1e-10, atol=1e-10, t_eval=np.array([t_min, tf]))\n",
    "        sol = solve_ivp(flat_extended_ode, (t_min, tf), x_logp_init, **solve_params)\n",
    "\n",
    "        x_logp_fin = sol.y[:, -1].reshape(n_data, mix.dim + 1)\n",
    "        x_fin, delta_logp = np.split(x_logp_fin, [mix.dim], -1)\n",
    "        prior_fin = np.log(prior.density(x_fin))\n",
    "        nll = -(delta_logp[:, 0] + prior_fin).mean()\n",
    "        \n",
    "        bpd_cst = 1.0 / (np.log(2.0) * mix.dim)\n",
    "        return x_fin,  nll * bpd_cst\n",
    "\n",
    "    num_batches = n_data // batch_size + (n_data % batch_size > 0)\n",
    "    seeds = np.random.SeedSequence(seed).spawn(num_batches)\n",
    "    nll = 0.0\n",
    "    for seed in seeds:\n",
    "        x_init = mix.sample(batch_size, seed)\n",
    "        x_fin, nll_batch = solve_batch(x_init)\n",
    "        nll += nll_batch\n",
    "\n",
    "    return x_fin, nll / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension 2 - VE\n",
      "tf=1.0: nll=-0.07914062447730236\n",
      "tf=20.0: nll=-0.2622657275358472\n",
      "tf=40.0: nll=-0.18390859378481877\n",
      "tf=60.0: nll=-0.030760761347738575\n",
      "tf=80.0: nll=0.1648992084007826\n",
      "tf=100.0: nll=0.3711655900300173\n",
      "Dimension 3 - VE\n",
      "tf=1.0: nll=-0.07219784221226758\n",
      "tf=20.0: nll=0.23539383185448318\n",
      "tf=40.0: nll=1.0760998209634547\n",
      "tf=60.0: nll=1.633057154259444\n",
      "tf=80.0: nll=2.0383644720132903\n",
      "tf=100.0: nll=2.355796112173455\n",
      "Dimension 4 - VE\n",
      "tf=1.0: nll=-0.06845292165460785\n",
      "tf=20.0: nll=1.1609602580799225\n",
      "tf=40.0: nll=2.1282864031483633\n",
      "tf=60.0: nll=2.7072008002496277\n",
      "tf=80.0: nll=3.1201214831174644\n",
      "tf=100.0: nll=3.4410697952916167\n",
      "Dimension 5 - VE\n",
      "tf=1.0: nll=-0.06802151657433862\n",
      "tf=20.0: nll=1.7762474955548995\n",
      "tf=40.0: nll=2.7628125023108927\n",
      "tf=60.0: nll=3.345287043698614\n",
      "tf=80.0: nll=3.7594537572157245\n",
      "tf=100.0: nll=4.080978802693484\n"
     ]
    }
   ],
   "source": [
    "for dim in range(2, 6):\n",
    "    print(f\"Dimension {dim} - VE\")\n",
    "    for tf in [1.0, 20.0, 40.0, 60.0, 80.0, 100.0]:\n",
    "        mix = VarianceExploding(cube_vertices(dim))\n",
    "        prior = MultivariateNormal(mix.dim, cov=mix.added_noise_sq(tf) * np.eye(mix.dim))\n",
    "\n",
    "        x_bw, nll = compute_quasi_exact_nll(mix, prior, tf=tf)\n",
    "        print(f\"tf={tf}: nll={nll}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension 2 - VP\n",
      "beta_max=10.0: nll=-0.27326817491199856\n",
      "beta_max=15.0: nll=-0.27413922948746283\n",
      "beta_max=20.0: nll=-0.27414448144653997\n",
      "beta_max=30.0: nll=-0.2741159980322\n",
      "beta_max=50.0: nll=-0.27410590111636657\n",
      "beta_max=80.0: nll=-0.2740964040274491\n",
      "Dimension 3 - VP\n",
      "beta_max=10.0: nll=-0.2760049894729151\n",
      "beta_max=15.0: nll=-0.2773749782937044\n",
      "beta_max=20.0: nll=-0.2775207680183966\n",
      "beta_max=30.0: nll=-0.2775350702249296\n",
      "beta_max=50.0: nll=-0.2775081909124967\n",
      "beta_max=80.0: nll=-0.2774680603326158\n",
      "Dimension 4 - VP\n",
      "beta_max=10.0: nll=-0.27010211192133377\n",
      "beta_max=15.0: nll=-0.2714160205702662\n",
      "beta_max=20.0: nll=-0.27151648916538873\n",
      "beta_max=30.0: nll=-0.27146231354730654\n",
      "beta_max=50.0: nll=-0.2713223260592701\n",
      "beta_max=80.0: nll=-0.27113440557137997\n",
      "Dimension 5 - VP\n",
      "beta_max=10.0: nll=-0.27073640184162556\n",
      "beta_max=15.0: nll=-0.27186124359031594\n",
      "beta_max=20.0: nll=-0.2718436379077664\n",
      "beta_max=30.0: nll=-0.27159617363947575\n",
      "beta_max=50.0: nll=-0.2711151657337706\n",
      "beta_max=80.0: nll=-0.27046852352293177\n"
     ]
    }
   ],
   "source": [
    "for dim in range(2, 6):\n",
    "    print(f\"Dimension {dim} - VP\")\n",
    "    for beta_max in [10.0, 15.0, 20.0, 30.0, 50.0, 80.0]:\n",
    "        mix = VariancePreserving(cube_vertices(dim), beta_max=beta_max)\n",
    "        prior = MultivariateNormal(mix.dim)\n",
    "\n",
    "        x_bw, nll = compute_quasi_exact_nll(mix, prior)\n",
    "        print(f\"beta_max={beta_max}: nll={nll}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
